Original file is located at
    https://colab.research.google.com/drive/1jGgF2bhavRYHWy0W1YFgHKzEDdw3f7W-
"""

!pip install google-cloud-texttospeech
!pip install pydub
!pip install python-dotenv
!pip install PyPDF2
!pip install vertexai
!apt-get install ffmpeg

##### Optimized Gemini with chunks and eleven labs audio

from google.colab import auth
auth.authenticate_user()
import os
import json
import re
import shutil
import PyPDF2
from google.cloud import texttospeech
from pydub import AudioSegment
from vertexai import init
from vertexai.generative_models import GenerativeModel, GenerationConfig
from dotenv import load_dotenv

"""#Load Env Variables"""

####
# Load environment variables from .env file
load_dotenv()
os.environ["GOOGLE_CLOUD_PROJECT"] = ""
os.environ["ELEVENLABS_API_KEY"]=""
# Access environment variables
project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY")

# ElevenLabs API configuration
elevenlabs_url = "https://api.elevenlabs.io/v1/text-to-speech"
elevenlabs_headers = {
    "Accept": "audio/mpeg",
    "Content-Type": "application/json",
    "xi-api-key": elevenlabs_api_key
}

# Voice IDs for ElevenLabs voices
speaker_voice_map = {
    "Joe": "IKne3meq5aSn9XLyUdCD",  # Male voice ID
    "Sarah": "21m00Tcm4TlvDq8ikWAM"    # Female voice ID
}

"""#Eleven Lab Voice Synthesis"""

# ElevenLabs TTS synthesis function
def synthesize_speech(text, speaker, index):
    voice_id = speaker_voice_map[speaker]
    data = {
        "text": text,
        "voice_settings": {
            "stability": 0.5,
            "similarity_boost": 0.75
        }
    }
    response = requests.post(f"{elevenlabs_url}/{voice_id}", json=data, headers=elevenlabs_headers)
    if response.status_code != 200:
        print(f"Error synthesizing speech for {speaker}: {response.text}")
        return
    filename = f"audio-files/{index}_{speaker}.mp3"
    with open(filename, "wb") as out:
        out.write(response.content)
    print(f'Audio content written to file "{filename}"')

"""# Split the article into manageble chunks"""

# Function to split text into manageable chunks while maintaining flow
def split_text_into_chunks(text, max_chars=4000):
    sentences = text.split('. ')
    chunks = []
    current_chunk = []

    for sentence in sentences:
        new_chunk = ". ".join(current_chunk + [sentence]) + "."
        if len(new_chunk) <= max_chars:
            current_chunk.append(sentence)
        else:
            chunks.append(". ".join(current_chunk) + ".")
            current_chunk = [sentence]

    if current_chunk:
        chunks.append(". ".join(current_chunk) + ".")
    return chunks

# Function to clean generated text
def clean_generated_text(raw_text):
    try:
        data = json.loads(raw_text)
        conversation = []
        if "podcastConversation" in data:
            for entry in data["podcastConversation"]:
                speaker = entry.get("speaker", "Unknown")
                dialogue = entry.get("dialogue", "").strip()
                if speaker and dialogue:
                    conversation.append({"speaker": speaker, "text": dialogue})
        return conversation
    except Exception as e:
        print(f"Error parsing text: {e}")
        return []

"""# Generate Audio"""

# Merge audio files into a single podcast
def merge_audios(audio_folder, output_file):
    combined = AudioSegment.empty()
    audio_files = sorted(
        [f for f in os.listdir(audio_folder) if f.endswith(".mp3")],
        key=lambda x: [int(c) if c.isdigit() else c for c in re.split(r'(\d+)', x)]
    )
    for filename in audio_files:
        audio_path = os.path.join(audio_folder, filename)
        print(f"Processing: {audio_path}")
        audio = AudioSegment.from_file(audio_path)
        combined += audio
    combined.export(output_file, format="mp3")
    print(f"Merged audio saved as {output_file}")

# Generate audio for the conversation
def generate_audio(conversation):
    if os.path.exists("audio-files"):
        shutil.rmtree("audio-files")
    os.makedirs("audio-files", exist_ok=True)

    for index, part in enumerate(conversation):
        speaker = part["speaker"]
        text = part["text"]
        synthesize_speech(text, speaker, index)

    merge_audios("audio-files", "podcast_output_elevenlabs2_geminichunk.mp3")

"""#System Prompt"""

# System prompt for Vertex AI
system_prompt = """You are generating a podcast conversation between Joe and Sarah.

**Guidelines**:
1. Joe provides detailed technical insights but avoids overusing analogies. Instead, focus on straightforward, clear explanations.
2. Sarah asks probing, thoughtful questions, occasionally offers her own insights, and challenges Joe to explain concepts simply and conversationally.
3. Both speakers use natural human speech patterns, including filler words like "um," "ah," "you know," and short pauses.
4. Conclude with a visionary statement highlighting the broader impact of the discussion on science and society.

**Focus**:
- Avoid excessive use of analogies. Use one or two if necessary for clarity but prioritize clear, direct explanations.
- Include natural conversational flow with interruptions, backtracking, and filler words to make the dialogue feel authentic.
- Encourage a natural dialogue with varied contributions from both speakers.

**Tone**:
- Engaging, relatable, and spontaneous.
- Emphasize human-like emotions, with occasional humor or lighthearted moments.
- Balance technical depth with conversational relatability, avoiding overly formal language.
"""

# Vertex AI configuration
generation_config = GenerationConfig(
    max_output_tokens=1200,
    temperature=0.7,
    top_p=0.95,
    response_mime_type="application/json"
)

# Extract text from PDF
def extract_text_from_pdf(pdf_file):
    text = ""
    with open(pdf_file, "rb") as file:
        pdf_reader = PyPDF2.PdfReader(file)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

"""#Generate Coversation"""

# Generate a conversation using the Gemini model
import pdb
def generate_conversation(article_text):
    init(project=project_id, location="us-central1")
    model = GenerativeModel(
        "gemini-1.5-flash-002",
        system_instruction=[system_prompt]
    )

    text_chunks = split_text_into_chunks(article_text)

    all_conversations = []
    last_response = ""
    speakers = ["Joe", "Sarah"]
    speaker_index = 0

    for index, chunk in enumerate(text_chunks):
        print(f"Processing chunk {index + 1} of {len(text_chunks)}...")
        prompt = f"{system_prompt}\n{speakers[speaker_index]}: {chunk}\n{speakers[(speaker_index + 1) % 2]}:"

        pdb.set_trace()
        if last_response:
            prompt = f"{system_prompt}\nPrevious response: {last_response}\n{prompt}"

        responses = model.generate_content(
            [prompt],
            generation_config=generation_config,
            stream=False,
        )

        raw_text = responses.candidates[0].content.parts[0].text
        print(f"\nRaw Text (Chunk {index + 1}): {raw_text}\n")

        conversation_chunk = clean_generated_text(raw_text)
        print(f"Cleaned Text (Chunk {index + 1}): {conversation_chunk}\n")

        all_conversations.extend(conversation_chunk)
        if conversation_chunk:
            last_response = conversation_chunk[-1]["text"]
        speaker_index = (speaker_index + 1) % 2

    print("\n--- Full Generated Conversation ---")
    for part in all_conversations:
        print(f"{part['speaker']}: {part['text']}")
    print("--- End of Conversation ---\n")

    return all_conversations

# Main execution
uploaded_pdf = "article.pdf"  # Replace with your PDF file
article_text = extract_text_from_pdf(uploaded_pdf)

# Generate conversation and audio
conversation = generate_conversation(article_text)
generate_audio(conversation)